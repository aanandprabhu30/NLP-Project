{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98221760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /opt/anaconda3/lib/python3.12/site-packages (3.9.1)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.12/site-packages (1.5.1)\n",
      "Requirement already satisfied: spacy in /opt/anaconda3/lib/python3.12/site-packages (3.8.5)\n",
      "Requirement already satisfied: pdfplumber in /opt/anaconda3/lib/python3.12/site-packages (0.11.6)\n",
      "Requirement already satisfied: transformers in /opt/anaconda3/lib/python3.12/site-packages (4.51.2)\n",
      "Requirement already satisfied: click in /opt/anaconda3/lib/python3.12/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/lib/python3.12/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/anaconda3/lib/python3.12/site-packages (from nltk) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from nltk) (4.66.5)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn) (2.2.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (1.0.12)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (8.3.6)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (0.9.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (2.8.2)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (75.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (24.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (3.5.0)\n",
      "Requirement already satisfied: pdfminer.six==20250327 in /opt/anaconda3/lib/python3.12/site-packages (from pdfplumber) (20250327)\n",
      "Requirement already satisfied: Pillow>=9.1 in /opt/anaconda3/lib/python3.12/site-packages (from pdfplumber) (10.4.0)\n",
      "Requirement already satisfied: pypdfium2>=4.18.0 in /opt/anaconda3/lib/python3.12/site-packages (from pdfplumber) (4.30.1)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from pdfminer.six==20250327->pdfplumber) (3.3.2)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from pdfminer.six==20250327->pdfplumber) (43.0.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.11.0)\n",
      "Requirement already satisfied: language-data>=1.2 in /opt/anaconda3/lib/python3.12/site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.20.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.1.31)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /opt/anaconda3/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /opt/anaconda3/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (5.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->spacy) (2.1.3)\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/anaconda3/lib/python3.12/site-packages (from cryptography>=36.0.0->pdfminer.six==20250327->pdfplumber) (1.17.1)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
      "Requirement already satisfied: pycparser in /opt/anaconda3/lib/python3.12/site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20250327->pdfplumber) (2.21)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk scikit-learn spacy pdfplumber transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "203822e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/aanandprabhu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import spacy.cli\n",
    "spacy.cli.download(\"en_core_web_sm\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32da552d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All set! Your libraries are working fine.\n",
      "Thanks!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import spacy\n",
    "import sklearn\n",
    "\n",
    "print(\"All set! Your libraries are working fine.\")\n",
    "print(\"Thanks!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a04118dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Discipline</th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>CS</td>\n",
       "      <td>Large Language Models (LLMs), such as ChatGPT ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>CS</td>\n",
       "      <td>Despite the success of deep learning in close-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>CS</td>\n",
       "      <td>Data analysis plays an indispensable role for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>CS</td>\n",
       "      <td>The goal of user experience design in industry...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>CS</td>\n",
       "      <td>Elliptic curve cryptosystems are considered an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID Discipline                                           Abstract\n",
       "0   1         CS  Large Language Models (LLMs), such as ChatGPT ...\n",
       "1   2         CS  Despite the success of deep learning in close-...\n",
       "2   3         CS  Data analysis plays an indispensable role for ...\n",
       "3   4         CS  The goal of user experience design in industry...\n",
       "4   5         CS  Elliptic curve cryptosystems are considered an..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"NLP_Abstract_Dataset (Discipline).csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19a9ac89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Abstract</th>\n",
       "      <th>cleaned_abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Large Language Models (LLMs), such as ChatGPT ...</td>\n",
       "      <td>large language models llms chatgpt bard revolu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Despite the success of deep learning in close-...</td>\n",
       "      <td>despite success deep learning close set object...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data analysis plays an indispensable role for ...</td>\n",
       "      <td>data analysis plays indispensable role underst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The goal of user experience design in industry...</td>\n",
       "      <td>goal user experience design industry improve c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Elliptic curve cryptosystems are considered an...</td>\n",
       "      <td>elliptic curve cryptosystems considered effici...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Abstract  \\\n",
       "0  Large Language Models (LLMs), such as ChatGPT ...   \n",
       "1  Despite the success of deep learning in close-...   \n",
       "2  Data analysis plays an indispensable role for ...   \n",
       "3  The goal of user experience design in industry...   \n",
       "4  Elliptic curve cryptosystems are considered an...   \n",
       "\n",
       "                                    cleaned_abstract  \n",
       "0  large language models llms chatgpt bard revolu...  \n",
       "1  despite success deep learning close set object...  \n",
       "2  data analysis plays indispensable role underst...  \n",
       "3  goal user experience design industry improve c...  \n",
       "4  elliptic curve cryptosystems considered effici...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#Load the english stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "#Pre-processing function\n",
    "def preprocess(text):\n",
    "    text = text.lower() #convert to lowercase\n",
    "    text = re.sub(r'[^a-z\\s]', ' ', text)  # remove non-letter characters\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # remove extra spaces\n",
    "    tokens = [word for word in text.split() if word not in stop_words]  # remove stopwords\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "\n",
    "# Apply preprocessing\n",
    "df['cleaned_abstract'] = df['Abstract'].apply(preprocess)\n",
    "\n",
    "# View sample result\n",
    "df[['Abstract', 'cleaned_abstract']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9b89329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Mapping: {'CS': 0, 'IS': 1, 'IT': 2}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Discipline</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>IS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>IS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>IS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>IS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>IS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>IT</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>IT</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>IT</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>IT</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>IT</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Discipline  label\n",
       "0          CS      0\n",
       "1          CS      0\n",
       "2          CS      0\n",
       "3          CS      0\n",
       "4          CS      0\n",
       "5          IS      1\n",
       "6          IS      1\n",
       "7          IS      1\n",
       "8          IS      1\n",
       "9          IS      1\n",
       "10         IT      2\n",
       "11         IT      2\n",
       "12         IT      2\n",
       "13         IT      2\n",
       "14         IT      2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#Create encoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "#Fit and transform the Discipline column\n",
    "df['label'] = le.fit_transform(df['Discipline'])\n",
    "\n",
    "#Shows the label mappings \n",
    "label_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(\"Label Mapping:\", label_mapping)\n",
    "\n",
    "#View the new column\n",
    "df[['Discipline', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbef7c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Matrix Shape: (15, 847)\n",
      "Example TF-IDF vector for first abstract:\n",
      " [0.         0.06231104 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.07392395 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.06231104 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.06231104 0.18693312 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.06231104 0.06231104 0.         0.         0.\n",
      " 0.         0.06231104 0.         0.         0.         0.06231104\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.06231104 0.         0.         0.         0.06231104 0.\n",
      " 0.         0.         0.         0.06231104 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.06231104 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.12462208\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.05410665 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.06231104 0.06231104 0.\n",
      " 0.         0.         0.         0.         0.         0.12462208\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.06231104 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.04377033\n",
      " 0.         0.06231104 0.         0.06852006 0.         0.\n",
      " 0.05410665 0.06231104 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.04828554 0.         0.\n",
      " 0.         0.06231104 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.06231104 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.05410665 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.06231104 0.06231104 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.10821329\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.04828554 0.         0.06231104 0.\n",
      " 0.         0.         0.06231104 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.04828554 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.06231104\n",
      " 0.         0.12462208 0.         0.06231104 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.06231104 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.06231104 0.         0.06231104\n",
      " 0.12462208 0.         0.         0.         0.06231104 0.\n",
      " 0.         0.         0.         0.         0.05410665 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.06231104 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.05410665 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.06231104 0.\n",
      " 0.         0.         0.06231104 0.         0.         0.\n",
      " 0.06231104 0.06231104 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.06231104 0.         0.\n",
      " 0.18693312 0.04828554 0.         0.         0.         0.05410665\n",
      " 0.         0.         0.         0.04828554 0.12462208 0.05410665\n",
      " 0.         0.         0.05410665 0.         0.12462208 0.49848833\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.06231104\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.06231104 0.         0.         0.         0.\n",
      " 0.05410665 0.         0.         0.         0.04008114 0.05410665\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.06231104 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.06231104 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.06231104\n",
      " 0.         0.         0.         0.         0.05948965 0.06231104\n",
      " 0.         0.12462208 0.         0.06231104 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.06231104 0.06231104 0.16231994 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.18693312 0.         0.05410665 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.05410665 0.         0.         0.05410665\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.06231104 0.         0.         0.         0.06231104 0.\n",
      " 0.         0.         0.         0.         0.04377033 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.05410665 0.         0.06231104 0.07392395 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.06231104 0.05410665 0.06231104 0.         0.         0.\n",
      " 0.06231104 0.06231104 0.         0.         0.         0.\n",
      " 0.         0.         0.06231104 0.         0.         0.\n",
      " 0.         0.05410665 0.         0.         0.         0.06231104\n",
      " 0.         0.32463988 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.06231104 0.\n",
      " 0.         0.         0.         0.06231104 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.06231104\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.06231104 0.         0.         0.05410665 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.04828554 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.05410665 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.06231104 0.05410665 0.         0.06231104\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.06231104 0.         0.05410665 0.\n",
      " 0.         0.         0.06231104 0.         0.         0.\n",
      " 0.         0.         0.06231104 0.         0.06231104 0.\n",
      " 0.         0.04377033 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.04377033 0.         0.\n",
      " 0.         0.04828554 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.09657107 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.18693312\n",
      " 0.06231104 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.04828554 0.         0.\n",
      " 0.        ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#Create the vectorizer\n",
    "vectorizer = TfidfVectorizer(\n",
    "    stop_words='english',   # remove common stop words like \"the\", \"is\", etc.\n",
    "    lowercase=True          # ensures all words are lowercase\n",
    ")\n",
    "\n",
    "#Fit the vectorizer on your cleaned abstracts and transform them into vectors\n",
    "X = vectorizer.fit_transform(df['cleaned_abstract'])\n",
    "\n",
    "#Check the result\n",
    "print(\"TF-IDF Matrix Shape:\", X.shape)  # Rows = abstracts, Columns = unique words\n",
    "print(\"Example TF-IDF vector for first abstract:\\n\", X.toarray()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2671291",
   "metadata": {},
   "source": [
    "### Model Comparison\n",
    "We compare two common classification algorithms:\n",
    "- Logistic Regression (baseline model)\n",
    "- Multinomial Naive Bayes (suitable for smaller datasets and text data)\n",
    "\n",
    "Both are trained on the same TF-IDF feature matrix and evaluated on a common test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eec09490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CS       1.00      1.00      1.00         1\n",
      "          IS       1.00      1.00      1.00         1\n",
      "          IT       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         3\n",
      "   macro avg       1.00      1.00      1.00         3\n",
      "weighted avg       1.00      1.00      1.00         3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#Define features and labels\n",
    "y = df['label']  #encoded discipline labels\n",
    "\n",
    "#Splits data into 80% training and 20% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "#Train a Logistic Regression classifier\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "#Evaluate the model\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "014b6964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CS       0.00      0.00      0.00         1\n",
      "          IS       1.00      1.00      1.00         1\n",
      "          IT       0.50      1.00      0.67         1\n",
      "\n",
      "    accuracy                           0.67         3\n",
      "   macro avg       0.50      0.67      0.56         3\n",
      "weighted avg       0.50      0.67      0.56         3\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aanandprabhu/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/aanandprabhu/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/aanandprabhu/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "#Train Naive Bayes on the same TF-IDF vectors\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "#Predict and evaluate\n",
    "y_pred_nb = nb_model.predict(X_test)\n",
    "\n",
    "#Print results\n",
    "print(\"Naive Bayes Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_nb, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0faaa52e",
   "metadata": {},
   "source": [
    "## 🔍 Model Comparison: Logistic Regression vs Naive Bayes\n",
    "\n",
    "To evaluate different classification strategies for predicting the research discipline (CS, IS, IT), we implemented and compared two widely used text classification models:\n",
    "\n",
    "### 1. **Logistic Regression**\n",
    "- Handles overlapping features better\n",
    "- Performs well with TF-IDF vectors\n",
    "- Requires more data but generalizes well\n",
    "\n",
    "### 2. **Multinomial Naive Bayes**\n",
    "- Simple and fast\n",
    "- Often preferred for small datasets and count-based features\n",
    "- Assumes word independence, which may limit performance with TF-IDF\n",
    "\n",
    "Both models were trained on the same TF-IDF feature matrix and evaluated using a common test set.\n",
    "\n",
    "The results are shown below using `classification_report`, comparing precision, recall, and F1-score across classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c83b12ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CS       1.00      1.00      1.00         1\n",
      "          IS       1.00      1.00      1.00         1\n",
      "          IT       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         3\n",
      "   macro avg       1.00      1.00      1.00         3\n",
      "weighted avg       1.00      1.00      1.00         3\n",
      "\n",
      "Naive Bayes Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CS       0.00      0.00      0.00         1\n",
      "          IS       1.00      1.00      1.00         1\n",
      "          IT       0.50      1.00      0.67         1\n",
      "\n",
      "    accuracy                           0.67         3\n",
      "   macro avg       0.50      0.67      0.56         3\n",
      "weighted avg       0.50      0.67      0.56         3\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aanandprabhu/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/aanandprabhu/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/aanandprabhu/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression Results:\")\n",
    "print(classification_report(y_test, y_pred, target_names=le.classes_))\n",
    "\n",
    "print(\"Naive Bayes Results:\")\n",
    "print(classification_report(y_test, y_pred_nb, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de5b8a7",
   "metadata": {},
   "source": [
    "### ✅ Key Takeaway: Initial Model Comparison on Prototype Dataset\n",
    "\n",
    "To validate the machine learning pipeline, both Logistic Regression and Multinomial Naive Bayes were implemented and evaluated using a small prototype dataset of 15 research abstracts.\n",
    "\n",
    "The goal at this stage was not to optimize performance, but to test end-to-end functionality — from text preprocessing to model evaluation — using TF-IDF feature extraction and `classification_report`.\n",
    "\n",
    "Despite the dataset’s limited size:\n",
    "- **Logistic Regression** correctly classified all test samples across all classes\n",
    "- **Naive Bayes** failed to predict one class (CS), resulting in lower overall accuracy and F1-score\n",
    "\n",
    "This preliminary comparison suggests that Logistic Regression is better suited to the TF-IDF-based feature space in this context. However, these results are **not statistically significant** due to the extremely small dataset and are intended only to demonstrate that the pipeline works.\n",
    "\n",
    "Further evaluation will be conducted once more data is added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69426a3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
