{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98221760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /opt/anaconda3/lib/python3.12/site-packages (3.9.1)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.12/site-packages (1.5.1)\n",
      "Requirement already satisfied: spacy in /opt/anaconda3/lib/python3.12/site-packages (3.8.5)\n",
      "Requirement already satisfied: pdfplumber in /opt/anaconda3/lib/python3.12/site-packages (0.11.6)\n",
      "Requirement already satisfied: transformers in /opt/anaconda3/lib/python3.12/site-packages (4.51.2)\n",
      "Requirement already satisfied: click in /opt/anaconda3/lib/python3.12/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/lib/python3.12/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/anaconda3/lib/python3.12/site-packages (from nltk) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from nltk) (4.66.5)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn) (2.2.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (1.0.12)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (8.3.6)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (0.9.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (2.8.2)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (75.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (24.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (3.5.0)\n",
      "Requirement already satisfied: pdfminer.six==20250327 in /opt/anaconda3/lib/python3.12/site-packages (from pdfplumber) (20250327)\n",
      "Requirement already satisfied: Pillow>=9.1 in /opt/anaconda3/lib/python3.12/site-packages (from pdfplumber) (10.4.0)\n",
      "Requirement already satisfied: pypdfium2>=4.18.0 in /opt/anaconda3/lib/python3.12/site-packages (from pdfplumber) (4.30.1)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from pdfminer.six==20250327->pdfplumber) (3.3.2)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from pdfminer.six==20250327->pdfplumber) (43.0.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.11.0)\n",
      "Requirement already satisfied: language-data>=1.2 in /opt/anaconda3/lib/python3.12/site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.20.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.1.31)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /opt/anaconda3/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /opt/anaconda3/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (5.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->spacy) (2.1.3)\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/anaconda3/lib/python3.12/site-packages (from cryptography>=36.0.0->pdfminer.six==20250327->pdfplumber) (1.17.1)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
      "Requirement already satisfied: pycparser in /opt/anaconda3/lib/python3.12/site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20250327->pdfplumber) (2.21)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk scikit-learn spacy pdfplumber transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "203822e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/aanandprabhu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import spacy.cli\n",
    "spacy.cli.download(\"en_core_web_sm\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32da552d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All set! Your libraries are working fine.\n",
      "Thanks!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import spacy\n",
    "import sklearn\n",
    "\n",
    "print(\"All set! Your libraries are working fine.\")\n",
    "print(\"Thanks!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a04118dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Discipline</th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>CS</td>\n",
       "      <td>Large Language Models (LLMs), such as ChatGPT ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>CS</td>\n",
       "      <td>Despite the success of deep learning in close-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>CS</td>\n",
       "      <td>Data analysis plays an indispensable role for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>CS</td>\n",
       "      <td>The goal of user experience design in industry...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>CS</td>\n",
       "      <td>Elliptic curve cryptosystems are considered an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID Discipline                                           Abstract\n",
       "0   1         CS  Large Language Models (LLMs), such as ChatGPT ...\n",
       "1   2         CS  Despite the success of deep learning in close-...\n",
       "2   3         CS  Data analysis plays an indispensable role for ...\n",
       "3   4         CS  The goal of user experience design in industry...\n",
       "4   5         CS  Elliptic curve cryptosystems are considered an..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"NLP_Abstract_Dataset (Discipline).csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3588be0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Abstract</th>\n",
       "      <th>cleaned_abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Large Language Models (LLMs), such as ChatGPT ...</td>\n",
       "      <td>large language models llms chatgpt bard revolu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Despite the success of deep learning in close-...</td>\n",
       "      <td>despite success deep learning close set object...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data analysis plays an indispensable role for ...</td>\n",
       "      <td>data analysis plays indispensable role underst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The goal of user experience design in industry...</td>\n",
       "      <td>goal user experience design industry improve c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Elliptic curve cryptosystems are considered an...</td>\n",
       "      <td>elliptic curve cryptosystems considered effici...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Abstract  \\\n",
       "0  Large Language Models (LLMs), such as ChatGPT ...   \n",
       "1  Despite the success of deep learning in close-...   \n",
       "2  Data analysis plays an indispensable role for ...   \n",
       "3  The goal of user experience design in industry...   \n",
       "4  Elliptic curve cryptosystems are considered an...   \n",
       "\n",
       "                                    cleaned_abstract  \n",
       "0  large language models llms chatgpt bard revolu...  \n",
       "1  despite success deep learning close set object...  \n",
       "2  data analysis plays indispensable role underst...  \n",
       "3  goal user experience design industry improve c...  \n",
       "4  elliptic curve cryptosystems considered effici...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#Load the english stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "#Pre-processing function\n",
    "def preprocess(text):\n",
    "    text = text.lower() #convert to lowercase\n",
    "    text = re.sub(r'[^a-z\\s]', ' ', text)  # remove non-letter characters\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # remove extra spaces\n",
    "    tokens = [word for word in text.split() if word not in stop_words]  # remove stopwords\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "\n",
    "# Apply preprocessing\n",
    "df['cleaned_abstract'] = df['Abstract'].apply(preprocess)\n",
    "\n",
    "# View sample result\n",
    "df[['Abstract', 'cleaned_abstract']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce7554e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Mapping: {'CS': 0, 'IS': 1, 'IT': 2}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Discipline</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>IS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>IS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>IS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>IS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>IS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>IT</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>IT</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>IT</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>IT</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>IT</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Discipline  label\n",
       "0          CS      0\n",
       "1          CS      0\n",
       "2          CS      0\n",
       "3          CS      0\n",
       "4          CS      0\n",
       "5          IS      1\n",
       "6          IS      1\n",
       "7          IS      1\n",
       "8          IS      1\n",
       "9          IS      1\n",
       "10         IT      2\n",
       "11         IT      2\n",
       "12         IT      2\n",
       "13         IT      2\n",
       "14         IT      2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#Create encoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "#Fit and transform the Discipline column\n",
    "df['label'] = le.fit_transform(df['Discipline'])\n",
    "\n",
    "#Shows the label mappings \n",
    "label_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(\"Label Mapping:\", label_mapping)\n",
    "\n",
    "#View the new column\n",
    "df[['Discipline', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9606993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Matrix Shape: (15, 847)\n",
      "Example TF-IDF vector for first abstract:\n",
      " [0.         0.06231104 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.07392395 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.06231104 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.06231104 0.18693312 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.06231104 0.06231104 0.         0.         0.\n",
      " 0.         0.06231104 0.         0.         0.         0.06231104\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.06231104 0.         0.         0.         0.06231104 0.\n",
      " 0.         0.         0.         0.06231104 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.06231104 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.12462208\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.05410665 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.06231104 0.06231104 0.\n",
      " 0.         0.         0.         0.         0.         0.12462208\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.06231104 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.04377033\n",
      " 0.         0.06231104 0.         0.06852006 0.         0.\n",
      " 0.05410665 0.06231104 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.04828554 0.         0.\n",
      " 0.         0.06231104 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.06231104 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.05410665 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.06231104 0.06231104 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.10821329\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.04828554 0.         0.06231104 0.\n",
      " 0.         0.         0.06231104 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.04828554 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.06231104\n",
      " 0.         0.12462208 0.         0.06231104 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.06231104 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.06231104 0.         0.06231104\n",
      " 0.12462208 0.         0.         0.         0.06231104 0.\n",
      " 0.         0.         0.         0.         0.05410665 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.06231104 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.05410665 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.06231104 0.\n",
      " 0.         0.         0.06231104 0.         0.         0.\n",
      " 0.06231104 0.06231104 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.06231104 0.         0.\n",
      " 0.18693312 0.04828554 0.         0.         0.         0.05410665\n",
      " 0.         0.         0.         0.04828554 0.12462208 0.05410665\n",
      " 0.         0.         0.05410665 0.         0.12462208 0.49848833\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.06231104\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.06231104 0.         0.         0.         0.\n",
      " 0.05410665 0.         0.         0.         0.04008114 0.05410665\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.06231104 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.06231104 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.06231104\n",
      " 0.         0.         0.         0.         0.05948965 0.06231104\n",
      " 0.         0.12462208 0.         0.06231104 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.06231104 0.06231104 0.16231994 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.18693312 0.         0.05410665 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.05410665 0.         0.         0.05410665\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.06231104 0.         0.         0.         0.06231104 0.\n",
      " 0.         0.         0.         0.         0.04377033 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.05410665 0.         0.06231104 0.07392395 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.06231104 0.05410665 0.06231104 0.         0.         0.\n",
      " 0.06231104 0.06231104 0.         0.         0.         0.\n",
      " 0.         0.         0.06231104 0.         0.         0.\n",
      " 0.         0.05410665 0.         0.         0.         0.06231104\n",
      " 0.         0.32463988 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.06231104 0.\n",
      " 0.         0.         0.         0.06231104 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.06231104\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.06231104 0.         0.         0.05410665 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.04828554 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.05410665 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.06231104 0.05410665 0.         0.06231104\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.06231104 0.         0.05410665 0.\n",
      " 0.         0.         0.06231104 0.         0.         0.\n",
      " 0.         0.         0.06231104 0.         0.06231104 0.\n",
      " 0.         0.04377033 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.04377033 0.         0.\n",
      " 0.         0.04828554 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.09657107 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.18693312\n",
      " 0.06231104 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.04828554 0.         0.\n",
      " 0.        ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#Create the vectorizer\n",
    "vectorizer = TfidfVectorizer(\n",
    "    stop_words='english',   # remove common stop words like \"the\", \"is\", etc.\n",
    "    lowercase=True          # ensures all words are lowercase\n",
    ")\n",
    "\n",
    "#Fit the vectorizer on your cleaned abstracts and transform them into vectors\n",
    "X = vectorizer.fit_transform(df['cleaned_abstract'])\n",
    "\n",
    "#Check the result\n",
    "print(\"TF-IDF Matrix Shape:\", X.shape)  # Rows = abstracts, Columns = unique words\n",
    "print(\"Example TF-IDF vector for first abstract:\\n\", X.toarray()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515b07bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
